{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profiling and Timing Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IPython provides access to a wide array of functionality for this kind of timing and profiling of code:\n",
    "\n",
    "- __``%time``__: Time the execution of a single statement\n",
    "- __``%timeit``__: Time repeated execution of a single statement for more accuracy\n",
    "- __``%prun``__: Run code with the profiler\n",
    "- __``%lprun``__: Run code with the line-by-line profiler\n",
    "- __``%memit``__: Measure the memory use of a single statement\n",
    "- __``%mprun``__: Run code with the line-by-line memory profiler\n",
    "\n",
    "The last four commands are not bundled with IPython–you'll need to get the ``line_profiler`` and ``memory_profiler`` extensions, which we will discuss in the following sections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timing Code Snippets: ``%timeit`` and ``%time``\n",
    "\n",
    "``%timeit`` line-magic and ``%%timeit`` cell-magic functions can be used to time the repeated execution of snippets of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "875 ns ± 2.31 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit sum(range(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: because this operation is so fast, __``%timeit`` automatically does a large number of repetitions.__\n",
    "For slower commands, ``%timeit`` will automatically adjust and perform fewer repetitions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "443 ms ± 2.97 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "total = 0\n",
    "for i in range(1000):\n",
    "    for j in range(1000):\n",
    "        total += i * (-1) ** j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Sometimes repeating an operation is not the best option.__\n",
    "For example, sorting a pre-sorted list is much faster than sorting an unsorted list, so the repetition will skew the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.82 ms ± 11.4 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "L = [random.random() for i in range(100000)]\n",
    "%timeit L.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this, __the ``%time`` magic function may be a better choice__. It also is a good choice for longer-running commands, when short, system-related delays are unlikely to affect the result.\n",
    "\n",
    "Let's time the sorting of an unsorted and a presorted list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorting an unsorted list:\n",
      "CPU times: user 44 ms, sys: 0 ns, total: 44 ms\n",
      "Wall time: 43.1 ms\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "L = [random.random() for i in range(100000)]\n",
    "print(\"sorting an unsorted list:\")\n",
    "%time L.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorting an already sorted list:\n",
      "CPU times: user 4 ms, sys: 0 ns, total: 4 ms\n",
      "Wall time: 5.25 ms\n"
     ]
    }
   ],
   "source": [
    "print(\"sorting an already sorted list:\")\n",
    "%time L.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Notice also how much longer the timing takes with ``%time`` versus ``%timeit``, even for the presorted list!__\n",
    "\n",
    "This is due to ``%timeit`` preventing system calls from interfering with the timing. (For example, garbage collection.)\n",
    "\n",
    "Both ``%time`` & ``%timeit`` accept the double-percent-sign cell magic syntax for multiline scripts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 416 ms, sys: 0 ns, total: 416 ms\n",
      "Wall time: 415 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "total = 0\n",
    "for i in range(1000):\n",
    "    for j in range(1000):\n",
    "        total += i * (-1) ** j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Profiling Full Scripts: ``%prun``\n",
    "\n",
    "IPython offers a way to use Python's built-in profiler with __``%prun``__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_of_lists(N):\n",
    "    total = 0\n",
    "    for i in range(5):\n",
    "        L = [j ^ (j >> i) for j in range(N)]\n",
    "        total += sum(L)\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    }
   ],
   "source": [
    "%prun sum_of_lists(1000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the notebook, the output is printed to the pager, and looks something like this:\n",
    "\n",
    "```\n",
    "14 function calls in 0.714 seconds\n",
    "\n",
    "   Ordered by: internal time\n",
    "\n",
    "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
    "        5    0.599    0.120    0.599    0.120 <ipython-input-19>:4(<listcomp>)\n",
    "        5    0.064    0.013    0.064    0.013 {built-in method sum}\n",
    "        1    0.036    0.036    0.699    0.699 <ipython-input-19>:1(sum_of_lists)\n",
    "        1    0.014    0.014    0.714    0.714 <string>:1(<module>)\n",
    "        1    0.000    0.000    0.714    0.714 {built-in method exec}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Line-By-Line Profiling with ``%lprun``\n",
    "\n",
    "The function-by-function profiling of ``%prun`` is useful, but __sometimes it's more convenient to have a line-by-line profile report__.\n",
    "This is not built into Python or IPython, but there is a ``line_profiler`` package available for installation that can do this.\n",
    "Start by using Python's packaging tool, ``pip``, to install the ``line_profiler`` package:\n",
    "\n",
    "```\n",
    "$ pip install line_profiler\n",
    "```\n",
    "\n",
    "Next, you can use IPython to load the ``line_profiler`` IPython extension, offered as part of this package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the ``%lprun`` command will do a line-by-line profiling of any function. __We need to tell it explicitly which functions we're interested in profiling__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%lprun -f sum_of_lists sum_of_lists(5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an example report:\n",
    "\n",
    "```\n",
    "Timer unit: 1e-06 s\n",
    "\n",
    "Total time: 0.009382 s\n",
    "File: <ipython-input-19-fa2be176cc3e>\n",
    "Function: sum_of_lists at line 1\n",
    "\n",
    "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
    "==============================================================\n",
    "     1                                           def sum_of_lists(N):\n",
    "     2         1            2      2.0      0.0      total = 0\n",
    "     3         6            8      1.3      0.1      for i in range(5):\n",
    "     4         5         9001   1800.2     95.9          L = [j ^ (j >> i) for j in range(N)]\n",
    "     5         5          371     74.2      4.0          total += sum(L)\n",
    "     6         1            0      0.0      0.0      return total\n",
    "```\n",
    "\n",
    "The information at the top gives us the key to reading the results: the time is reported in microseconds and we can see where the program is spending the most time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Profiling Memory Use: ``%memit`` and ``%mprun``\n",
    "\n",
    "__Another aspect of profiling is the amount of memory an operation uses.__ This can be evaluated with the ``memory_profiler`` extension.\n",
    "\n",
    "Start by ``pip``-installing the extension:\n",
    "```\n",
    "$ pip install memory_profiler\n",
    "```\n",
    "Then use IPython to load the extension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The memory profiler contains two useful magic functions: __``%memit`` magic (a memory-measuring equivalent of ``%timeit``)__ and __``%mprun`` function (a memory-measuring equivalent of ``%lprun``)__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 130.64 MiB, increment: 76.29 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit sum_of_lists(1000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that this function uses about 130 MB of memory.\n",
    "\n",
    "__For a line-by-line description of memory use__, we can use the ``%mprun`` magic.\n",
    "\n",
    "__Unfortunately, this magic works only for functions defined in separate modules__ rather than the notebook itself. __Start by using ``%%file`` to create a module called ``mprun_demo.py``, which contains our ``sum_of_lists`` function__, with one addition that will make our memory profiling results more clear:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing mprun_demo.py\n"
     ]
    }
   ],
   "source": [
    "%%file mprun_demo.py\n",
    "def sum_of_lists(N):\n",
    "    total = 0\n",
    "    for i in range(5):\n",
    "        L = [j ^ (j >> i) for j in range(N)]\n",
    "        total += sum(L)\n",
    "        del L # remove reference to L\n",
    "    return total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now import the new version of this function and run the memory line profiler:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from mprun_demo import sum_of_lists\n",
    "%mprun -f sum_of_lists sum_of_lists(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example report:\n",
    "```\n",
    "Filename: ./mprun_demo.py\n",
    "\n",
    "Line #    Mem usage    Increment   Line Contents\n",
    "================================================\n",
    "     4     71.9 MiB      0.0 MiB           L = [j ^ (j >> i) for j in range(N)]\n",
    "\n",
    "\n",
    "Filename: ./mprun_demo.py\n",
    "\n",
    "Line #    Mem usage    Increment   Line Contents\n",
    "================================================\n",
    "     1     39.0 MiB      0.0 MiB   def sum_of_lists(N):\n",
    "     2     39.0 MiB      0.0 MiB       total = 0\n",
    "     3     46.5 MiB      7.5 MiB       for i in range(5):\n",
    "     4     71.9 MiB     25.4 MiB           L = [j ^ (j >> i) for j in range(N)]\n",
    "     5     71.9 MiB      0.0 MiB           total += sum(L)\n",
    "     6     46.5 MiB    -25.4 MiB           del L # remove reference to L\n",
    "     7     39.1 MiB     -7.4 MiB       return total\n",
    "```\n",
    "\n",
    "The ``Increment`` column tells us how much each line affects the total memory budget: observe that when we create and delete the list ``L``, we are adding about 25 MB of memory usage.\n",
    "\n",
    "This is on top of the background memory usage from the Python interpreter itself."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
